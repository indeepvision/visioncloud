"use strict";(self.webpackChunk_indeepvision_visioncloud_docs=self.webpackChunk_indeepvision_visioncloud_docs||[]).push([[897],{2247:(e,t,n)=>{n.d(t,{xA:()=>u,yg:()=>y});var a=n(4041);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function l(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?l(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):l(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function r(e,t){if(null==e)return{};var n,a,i=function(e,t){if(null==e)return{};var n,a,i={},l=Object.keys(e);for(a=0;a<l.length;a++)n=l[a],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(a=0;a<l.length;a++)n=l[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}var s=a.createContext({}),g=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},u=function(e){var t=g(e.components);return a.createElement(s.Provider,{value:t},e.children)},c="mdxType",p={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},d=a.forwardRef((function(e,t){var n=e.components,i=e.mdxType,l=e.originalType,s=e.parentName,u=r(e,["components","mdxType","originalType","parentName"]),c=g(n),d=i,y=c["".concat(s,".").concat(d)]||c[d]||p[d]||l;return n?a.createElement(y,o(o({ref:t},u),{},{components:n})):a.createElement(y,o({ref:t},u))}));function y(e,t){var n=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var l=n.length,o=new Array(l);o[0]=d;var r={};for(var s in t)hasOwnProperty.call(t,s)&&(r[s]=t[s]);r.originalType=e,r[c]="string"==typeof e?e:i,o[1]=r;for(var g=2;g<l;g++)o[g]=n[g];return a.createElement.apply(null,o)}return a.createElement.apply(null,n)}d.displayName="MDXCreateElement"},5651:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>o,default:()=>p,frontMatter:()=>l,metadata:()=>r,toc:()=>g});var a=n(9575),i=(n(4041),n(2247));const l={sidebar_position:1},o="Classification",r={unversionedId:"user-guide/available-models/classification",id:"user-guide/available-models/classification",title:"Classification",description:"What it does: Assigns a single category label to an entire image.",source:"@site/docs/user-guide/available-models/classification.md",sourceDirName:"user-guide/available-models",slug:"/user-guide/available-models/classification",permalink:"/visioncloud/docs/user-guide/available-models/classification",draft:!1,tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1},sidebar:"userGuide",previous:{title:"Choosing a Model Type",permalink:"/visioncloud/docs/user-guide/available-models/choosing-model-type"},next:{title:"Segmentation",permalink:"/visioncloud/docs/user-guide/available-models/segmentation"}},s={},g=[{value:"Input",id:"input",level:2},{value:"Labels",id:"labels",level:3},{value:"Output",id:"output",level:2},{value:"How it looks in the platform",id:"how-it-looks-in-the-platform",level:3},{value:"When to Use Classification",id:"when-to-use-classification",level:2},{value:"Example Use Cases",id:"example-use-cases",level:3},{value:"Image Classification Models",id:"image-classification-models",level:2},{value:"Considerations for Training",id:"considerations-for-training",level:2},{value:"Additional Configuration",id:"additional-configuration",level:2}],u={toc:g},c="wrapper";function p(e){let{components:t,...n}=e;return(0,i.yg)(c,(0,a.A)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,i.yg)("h1",{id:"classification"},"Classification"),(0,i.yg)("p",null,(0,i.yg)("strong",{parentName:"p"},"What it does:")," Assigns a single category label to an entire image."),(0,i.yg)("h2",{id:"input"},"Input"),(0,i.yg)("p",null,"A whole image (e.g., a photo of a product on a conveyor belt)"),(0,i.yg)("h3",{id:"labels"},"Labels"),(0,i.yg)("p",null,"This model expects image-level labels, such as:  "),(0,i.yg)("ul",null,(0,i.yg)("li",{parentName:"ul"},'"defective" vs "good"  '),(0,i.yg)("li",{parentName:"ul"},'"product_type_A" vs "product_type_B"  '),(0,i.yg)("li",{parentName:"ul"},'"empty" vs "product_present"  ')),(0,i.yg)("admonition",{title:"Labeling Tips",type:"tip"},(0,i.yg)("ul",{parentName:"admonition"},(0,i.yg)("li",{parentName:"ul"},'Use clear and consistent labels: e.g., always "good" instead of mixing "ok", "okay", etc.  '),(0,i.yg)("li",{parentName:"ul"},"Avoid ambiguous labels; uncertain images can confuse the model  "),(0,i.yg)("li",{parentName:"ul"},"Review labels before training to prevent errors  "))),(0,i.yg)("h2",{id:"output"},"Output"),(0,i.yg)("p",null,'A class label (e.g., "defective", "good", "product_type_A")'),(0,i.yg)("h3",{id:"how-it-looks-in-the-platform"},"How it looks in the platform"),(0,i.yg)("ul",null,(0,i.yg)("li",{parentName:"ul"},"The model returns a single label for each uploaded image  "),(0,i.yg)("li",{parentName:"ul"},"Confidence scores are provided for each class (optional display)  ")),(0,i.yg)("h2",{id:"when-to-use-classification"},"When to Use Classification"),(0,i.yg)("p",null,"Use Classification when you need to:  "),(0,i.yg)("p",null,"\u2705 ",(0,i.yg)("strong",{parentName:"p"},"Know what\u2019s in the image, without locating it"),(0,i.yg)("br",{parentName:"p"}),"\n","\u2705 ",(0,i.yg)("strong",{parentName:"p"},"Make a single decision per image")," \u2013 One dominant object or condition",(0,i.yg)("br",{parentName:"p"}),"\n","\u2705 ",(0,i.yg)("strong",{parentName:"p"},"Detect presence or absence"),' \u2013 "Is there a product?" "Is the cap on?"',(0,i.yg)("br",{parentName:"p"}),"\n","\u2705 ",(0,i.yg)("strong",{parentName:"p"},"Perform binary quality control")," \u2013 Pass/fail, good/defective  "),(0,i.yg)("h3",{id:"example-use-cases"},"Example Use Cases"),(0,i.yg)("div",{style:{display:"flex",justifyContent:"center"}},(0,i.yg)("table",null,(0,i.yg)("thead",null,(0,i.yg)("tr",null,(0,i.yg)("th",null,"Application"),(0,i.yg)("th",null,"What It Classifies"))),(0,i.yg)("tbody",null,(0,i.yg)("tr",null,(0,i.yg)("td",null,"Product presence"),(0,i.yg)("td",null,'"Empty" vs "Product present"')),(0,i.yg)("tr",null,(0,i.yg)("td",null,"Overall quality"),(0,i.yg)("td",null,'"Good" vs "Defective"')),(0,i.yg)("tr",null,(0,i.yg)("td",null,"Product type"),(0,i.yg)("td",null,'"Type A" vs "Type B" vs "Type C"')),(0,i.yg)("tr",null,(0,i.yg)("td",null,"Orientation"),(0,i.yg)("td",null,'"Upright" vs "Tilted" vs "Fallen"'))))),(0,i.yg)("admonition",{title:"When to Avoid Classification",type:"caution"},(0,i.yg)("p",{parentName:"admonition"},(0,i.yg)("strong",{parentName:"p"},"Limitations:"),"  "),(0,i.yg)("ul",{parentName:"admonition"},(0,i.yg)("li",{parentName:"ul"},"\u274c Cannot locate defects or objects  "),(0,i.yg)("li",{parentName:"ul"},"\u274c Cannot handle multiple objects in the same image  "),(0,i.yg)("li",{parentName:"ul"},"\u274c Does not provide spatial information  "),(0,i.yg)("li",{parentName:"ul"},"\u274c Cannot distinguish between multiple instances  "),(0,i.yg)("li",{parentName:"ul"},"\u274c Less robust \u2013 relies only on global image features  "),(0,i.yg)("li",{parentName:"ul"},"\u274c Needs enough images per class (minimum ~50-100 recommended)  "),(0,i.yg)("li",{parentName:"ul"},"\u274c Sensitive to class imbalance \u2013 rare classes may be misclassified  "),(0,i.yg)("li",{parentName:"ul"},"\u274c Image resolution affects accuracy; very small images may reduce performance  ")),(0,i.yg)("p",{parentName:"admonition"},(0,i.yg)("strong",{parentName:"p"},"Better alternatives:"),(0,i.yg)("br",{parentName:"p"}),"\n","Prefer ",(0,i.yg)("strong",{parentName:"p"},"Segmentation")," or ",(0,i.yg)("strong",{parentName:"p"},"Instance Segmentation")," because they:  "),(0,i.yg)("ul",{parentName:"admonition"},(0,i.yg)("li",{parentName:"ul"},"\u2705 Provide geometric information (shape, size, position)  "),(0,i.yg)("li",{parentName:"ul"},"\u2705 Leverage color and spatial features  "),(0,i.yg)("li",{parentName:"ul"},"\u2705 Are more accurate and robust  "),(0,i.yg)("li",{parentName:"ul"},"\u2705 Can be simplified to classification if only detection is needed  ")),(0,i.yg)("p",{parentName:"admonition"},(0,i.yg)("strong",{parentName:"p"},"Exception:")," Use Classification only for very simple cases where a ",(0,i.yg)("strong",{parentName:"p"},"single image-level decision")," is enough and localization is not required.  ")),(0,i.yg)("h2",{id:"image-classification-models"},"Image Classification Models"),(0,i.yg)("div",{style:{display:"flex",justifyContent:"center"}},(0,i.yg)("table",null,(0,i.yg)("thead",null,(0,i.yg)("tr",null,(0,i.yg)("th",null,"Model"),(0,i.yg)("th",null,"Use for"),(0,i.yg)("th",null,"Example Applications"),(0,i.yg)("th",null,"Input"),(0,i.yg)("th",null,"Output"))),(0,i.yg)("tbody",null,(0,i.yg)("tr",null,(0,i.yg)("td",null,"Generic classification"),(0,i.yg)("td",null,"Product categorization, quality grading, scene recognition"),(0,i.yg)("td",null,"Sorting products by type, identifying defective vs normal items"),(0,i.yg)("td",null,"Whole images"),(0,i.yg)("td",null,"Class labels with confidence scores")),(0,i.yg)("tr",null,(0,i.yg)("td",null,"Dynamic classification"),(0,i.yg)("td",null,"Applications where categories may evolve over time"),(0,i.yg)("td",null,"Detecting new product variants, adapting to seasonal changes"),(0,i.yg)("td",null,"Whole images"),(0,i.yg)("td",null,"Adaptable class labels with confidence scores")),(0,i.yg)("tr",null,(0,i.yg)("td",null,"Generic classification embedding"),(0,i.yg)("td",null,"Similarity search, clustering, anomaly detection"),(0,i.yg)("td",null,"Finding visually similar products, spotting unusual items"),(0,i.yg)("td",null,"Whole images"),(0,i.yg)("td",null,"Feature vectors that capture image characteristics"))))),(0,i.yg)("h2",{id:"considerations-for-training"},"Considerations for Training"),(0,i.yg)("ul",null,(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("strong",{parentName:"li"},"Input size:")," Typically 224x224 or 256x256 px; larger sizes can improve accuracy but increase computation."),(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("strong",{parentName:"li"},"Data augmentation:")," Rotations, flips, and color changes improve model robustness."),(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("strong",{parentName:"li"},"Class balance:")," Ensure all classes have enough examples to avoid bias."),(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("strong",{parentName:"li"},"Transfer learning:")," Using pre-trained models speeds up training and improves performance."),(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("strong",{parentName:"li"},"Batch size and learning rate:")," Experiment to optimize training efficiency."),(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("strong",{parentName:"li"},"Regularization:")," Dropout or weight decay to prevent overfitting.")),(0,i.yg)("h2",{id:"additional-configuration"},"Additional Configuration"),(0,i.yg)("ul",null,(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("strong",{parentName:"li"},"Dynamic classification:")," Ensure proper label mapping and update logic for evolving classes.")))}p.isMDXComponent=!0}}]);